\chapter{Introdução}
Os avanças nas tecnologias de informação permitiram o armazenamento de grandes e
variados conjuntos de dados. Com o advento da \textit{internet}, interações
\textit{online} são cada vez mais presentes no cotidiano, possibilitando a
comunicação entre pessoas e empresas de maneira fácil e descomplicada. Como
consequência dessa interatividade, a quantidade de dados tem crescido a uma taxa
significativa durante os últimos anos, de acordo com Goldschimidt e Bezerra
(\citeyear{goldschmidt2015data}).

Estes dados, os quais podem ir desde manifestações em redes sociais até
movimentações financeiras, são gerados e disponibilizados em diferentes tamanhos
e formatos. De acordo com McAfee (\citeyear{mcafee2012big}), através desses
dados gerentes podem medir e conhecer radicalmente seus negócios e 
consequentemente, traduzir esse conhecimento em decisões melhores para seus 
negócios.

Porém, a realização das etapas necessárias para extrair conhecimento a
partir desses dados implica em altos custos econômicos e computacionais, uma vez
que o armazenamento e processamento dos mesmos não são tarefas triviais. De
acordo com Oussous et al. (\citeyear{oussous2018big}), essas dificuldades afetam
a captura de dados, armazenamento, pesquisa, compartilhamento, análise, gerência
e visualização dessas informações. Além disso, a segurança e provacidade são
problemas em aplicações guiadas a dados.

O processamento dessas informações requer ferramentas capazes de recorrer ao
processamento paralelo e distribuído entre um conjunto de máquinas
(\textit{cluster}), além de suportar altas variações no volume de dados
utilizado. \textit{Frameworks} baseados no paradigma \textit{MapReduce}, como o
Apache Hadoop, têm sido amplamente utilizados para o processamento de grandes
volumes de dados. De forma geral, esses \textit{frameworks} oferecem operações
de processamento de alto nível e abstrações para acesso aos recursos do
\textit{cluster} com o objetivo de facilitar o desenvolvimento de aplicações
pelos usuários.

Entretanto, segundo Zaharia et al. (\citeyear{zaharia2012rdd}), esses 
\textit{frameworks} falham em oferecer abstrações para acesso à memória 
distribuída tornando-os ineficientes no processamento de algoritmos de reuso, 
como aqueles utilizados em Mineração de Dados e Aprendizado de Máquina. 
Nesse sentido, o Apache Spark\footnote{Disponível em: https://spark.apache.org/}
surge como um \textit{framework} capaz de processar de grandes quantidades de 
dados de maneira paralela e distribuída estendendo o modelo \textit{MapReduce}, 
já consolidado pelo Apache Hadoop, de modo a facilitar o desenvolvimento de 
aplicações com estas características.

O Spark foi pensado e projetado para implementar um mecanismo de execução
multiestágio em memória principal, onde juntamente com sua principal abstração,
o \textit{Resilient Distributed Datasets} Zaharia et al. 
(\citeyear{zaharia2012rdd}) (RDD), permite que diversas computações sejam 
realizadas em memória, dispensando a escrita de dados intermediários em disco. 
Dessa forma, o Spark consegue alcançar um desempenho superior quando comparado 
ao mecanismo baseado em disco utilizado pelo Hadoop. 

Um RDD consiste em uma coleção imutável de objetos, os quais podem ser operados
e processados de forma paralela e distribuída entre os nós do \textit{cluster}.
Uma vez realizado o processamento de um determinado RDD, este pode ser mantido
em \textit{cache} para que seja possível reutilizá-lo em futuras computações sem
necessidade de realizar a sua recomputação. Por padrão, o nível de armazenamento
utilizado pelo Spark para o \textit{caching} de dados é apenas a memória
principal, podendo ser alterado para armazenamento estável ou uma combinação de
ambos. 

Conforme novos RDDs são armazenados e processados, a memória disponível tende a
ficar esgotada e, portanto, políticas de gerenciamento de memória devem ser
utilizadas. Assim, em situações de sobrecarga no uso do espaço disponível, o
Spark remove partições mantidas em \textit{cache} de acordo com o algoritmo LRU
(\textit{Least Recently Used}) Luu Hien. (\citeyear{luu2018beginning}). 
Desta forma, é possível gerar situações onde apenas uma fração do RDD permanece 
armazenado em \textit{cache}.

